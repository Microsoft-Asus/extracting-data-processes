{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from robobrowser import RoboBrowser\n",
    "import bs4\n",
    "import re\n",
    "import linkGrabber\n",
    "import requests\n",
    "import random\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import bleach\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2020-05-21\n"
     ]
    }
   ],
   "source": [
    "today = date.today()\n",
    "print(\"Today's date:\", today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = requests.get(\"https://indianexpress.com/section/technology/tech-news-technology/\")\n",
    "soup = bs4.BeautifulSoup(src.content , 'lxml')\n",
    "\n",
    "urls=[]\n",
    "for h2_tag in soup.find_all(\"h2\"):\n",
    "    a_tag = h2_tag.find('a')\n",
    "    urls.append(str(a_tag.attrs['href']))\n",
    "    \n",
    "random_choice1=(random.choice(urls))\n",
    "random_choice2=(random.choice(urls))\n",
    "random_choice3=(random.choice(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "br= RoboBrowser()\n",
    "br.open(\"http://classroom.campusx.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tuhin\\Anaconda3\\lib\\site-packages\\robobrowser\\browser.py:40: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 40 of the file C:\\Users\\tuhin\\Anaconda3\\lib\\site-packages\\robobrowser\\browser.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  features=self.browser.parser,\n"
     ]
    }
   ],
   "source": [
    "#login\n",
    "\n",
    "form = br.get_form()\n",
    "form['email']='tuhinmukherjee744@gmail.com'\n",
    "form['password']='yeyC32'\n",
    "br.submit_form(form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "src=str(br.parsed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.5\n"
     ]
    }
   ],
   "source": [
    "#Extracting Current Marks\n",
    "\n",
    "start = '<span class=\"right display-4\">'\n",
    "end = '</span>'\n",
    "result = re.search('%s(.*)%s'%(start, end),src).group(1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gyan have bben submitted today\n"
     ]
    }
   ],
   "source": [
    "#Gyaan upload \n",
    "\n",
    "\n",
    "br.open(\"http://classroom.campusx.in/gyan\")\n",
    "\n",
    "#upload gyan tr1\n",
    "form = br.get_form()\n",
    "form['gyanlink']=random_choice1\n",
    "br.submit_form(form)\n",
    "\n",
    "#upload gyan tr2\n",
    "form = br.get_form()\n",
    "form['gyanlink']=random_choice2\n",
    "br.submit_form(form)\n",
    "\n",
    "#upload gyan tr3\n",
    "form = br.get_form()\n",
    "form['gyanlink']=random_choice3\n",
    "br.submit_form(form)\n",
    "\n",
    "src=str(br.parsed())\n",
    "soup = bs4.BeautifulSoup(src, 'lxml')\n",
    "\n",
    "alert = soup.find('div', class_=\"alert alert-warning alert-dismissible\")\n",
    "msg=alert.text\n",
    "if msg=='\\n√ó\\n\\n    You have already shared today. Try again tomorrow\\n':\n",
    "    print (\"Gyan have bben submitted today\")\n",
    "else:\n",
    "    print (\"Gyan not submitted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click_module\n",
    "\n",
    "br.open(\"http://classroom.campusx.in/gyan\")\n",
    "src=str(br.parsed())\n",
    "soup = bs4.BeautifulSoup(src, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hiting gyan links for Ritayan \n",
    "\n",
    "url=[]\n",
    "\n",
    "for cell in soup.find_all(\"div\", class_=\"card-body\"): \n",
    "    name = \"\"\n",
    "    a_tag=''\n",
    "    \n",
    "    namecell = cell.find(\"h6\", class_=\"card-title\", text='Ritayan Dhara')\n",
    "    if namecell is not None:\n",
    "        name = namecell.get_text(strip=True)\n",
    "        a_tag = cell.find('a')\n",
    "        url.append(str(a_tag.attrs['href']))\n",
    "            \n",
    "    #print(a_tag)\n",
    "    \n",
    "url_to_hit1=url[0]\n",
    "url_to_hit2=url[1]\n",
    "url_to_hit3=url[2]\n",
    "url_to_hit4=url[3]\n",
    "url_to_hit5=url[4]\n",
    "link_generated1=('http://classroom.campusx.in'+url_to_hit1)\n",
    "link_generated2=('http://classroom.campusx.in'+url_to_hit2)\n",
    "link_generated3=('http://classroom.campusx.in'+url_to_hit3)\n",
    "link_generated4=('http://classroom.campusx.in'+url_to_hit4)\n",
    "link_generated5=('http://classroom.campusx.in'+url_to_hit5)\n",
    "br.open(link_generated1)\n",
    "br.open(link_generated2)\n",
    "br.open(link_generated3)\n",
    "br.open(link_generated4)\n",
    "br.open(link_generated5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hiting gyan links for Wasif\n",
    "\n",
    "url=[]\n",
    "\n",
    "for cell in soup.find_all(\"div\", class_=\"card-body\"): \n",
    "    name = \"\"\n",
    "    a_tag=''\n",
    "    \n",
    "    namecell = cell.find(\"h6\", class_=\"card-title\", text='Wasif Ekbal')\n",
    "    if namecell is not None:\n",
    "        name = namecell.get_text(strip=True)\n",
    "        a_tag = cell.find('a')\n",
    "        url.append(str(a_tag.attrs['href']))\n",
    "            \n",
    "    #print(a_tag)\n",
    "    \n",
    "url_to_hit1=url[0]\n",
    "url_to_hit2=url[1]\n",
    "url_to_hit3=url[2]\n",
    "url_to_hit4=url[3]\n",
    "url_to_hit5=url[4]\n",
    "link_generated1=('http://classroom.campusx.in'+url_to_hit1)\n",
    "link_generated2=('http://classroom.campusx.in'+url_to_hit2)\n",
    "link_generated3=('http://classroom.campusx.in'+url_to_hit3)\n",
    "link_generated4=('http://classroom.campusx.in'+url_to_hit4)\n",
    "link_generated5=('http://classroom.campusx.in'+url_to_hit5)\n",
    "br.open(link_generated1)\n",
    "br.open(link_generated2)\n",
    "br.open(link_generated3)\n",
    "br.open(link_generated4)\n",
    "br.open(link_generated5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data\n",
    "\n",
    "br.open(\"http://classroom.campusx.in/dashboard\")\n",
    "src=str(br.parsed())\n",
    "soup = bs4.BeautifulSoup(src, 'lxml')\n",
    "leaderboard = soup.find('table', class_='table')\n",
    "name=[]\n",
    "score=[]\n",
    "for each_candidate in leaderboard.find_all('tbody'):\n",
    "    rows = each_candidate.find_all('tr')\n",
    "    for row in rows:\n",
    "        name.append(row.find_all('td')[1].text.strip())\n",
    "        score.append(row.find_all('td')[2].text.strip())\n",
    "        \n",
    "final=pd.DataFrame()\n",
    "d={'name':name,'score':score,'My_name':'Tuhin','My_score':result,'Date':today}\n",
    "df=pd.DataFrame(d)\n",
    "final=final.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('data of'+str(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
